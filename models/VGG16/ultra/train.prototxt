name: "VGG16"
layer {
  name: 'input-data'
  type: 'Python'
  top: 'data'
  top: 'im_info'
  top: 'gt_boxes'
  top: 'gt_masks'
  top: 'mask_info'
  python_param {
    module: 'pylayer.mnc_data_layer'
    layer: 'MNCDataLayer'
    param_str: "{ 'num_classes': 2 }"
  }
}

# ------------ Convolution -----------

layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}

layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}

layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}

layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}

layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}

layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}

layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}

layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}

layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}

layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}

layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}

layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}

#------------ RPN ------------

layer {
  name: "rpn_conv_3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn_output"
  param { lr_mult: 1.0 }
  param { lr_mult: 2.0 }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_relu_3x3"
  type: "ReLU"
  bottom: "rpn_output"
  top: "rpn_output"
}

layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn_output"
  top: "rpn_cls_score"
  param { lr_mult: 1.0 }
  param { lr_mult: 2.0 }
  convolution_param {
    num_output: 18   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn_output"
  top: "rpn_bbox_pred"
  param { lr_mult: 1.0 }
  param { lr_mult: 2.0 }
  convolution_param {
    num_output: 36   # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
   bottom: "rpn_cls_score"
   top: "rpn_cls_score_reshape"
   name: "rpn_cls_score_reshape"
   type: "Reshape"
   reshape_param { shape { dim: 0 dim: 2 dim: -1 dim: 0 } }
}

#------------ Anchor to Proposal ------------

layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}

layer {
  name: 'rpn_cls_prob_reshape'
  type: 'Reshape'
  bottom: 'rpn_cls_prob'
  top: 'rpn_cls_prob_reshape'
  reshape_param { shape { dim: 0 dim: 18 dim: -1 dim: 0 } }
}

layer {
  name: 'proposal'
  type: 'Python'
  bottom: 'rpn_cls_prob_reshape'
  bottom: 'rpn_bbox_pred'
  bottom: 'im_info'
  propagate_down: 0
  propagate_down: 1
  propagate_down: 0
  top: 'rpn_rois'
  top: 'rpn_rois_index'
  python_param {
    module: 'pylayer.proposal_layer'
    layer: 'ProposalLayer'
    param_str: "{ 'feat_stride': 16, 'use_clip': 1, 'clip_base': 512 }"
  }
}

layer {
  name: 'roi-data'
  type: 'Python'
  bottom: 'rpn_rois'
  bottom: 'gt_boxes'
  bottom: 'im_info'
  bottom: 'gt_masks'
  bottom: 'mask_info'
  bottom: 'rpn_rois_index'
  propagate_down: 1
  propagate_down: 0
  propagate_down: 0
  propagate_down: 0
  propagate_down: 0
  propagate_down: 0
  top: 'rois'
  top: 'labels'
  top: 'bbox_targets'
  top: 'bbox_inside_weights'
  top: 'bbox_outside_weights'
  top: 'mask_targets'
  top: 'mask_weight'
  top: 'gt_masks_info'
  top: 'fg_inds'
  top: 'bg_inds'
  python_param {
    module: 'pylayer.proposal_target_layer'
    layer: 'ProposalTargetLayer'
    param_str: "{'num_classes': 2, 'bp_all': 1}"
  }
}

layer {
  name: 'rpn-data'
  type: 'Python'
  bottom: 'rpn_cls_score'
  bottom: 'gt_boxes'
  bottom: 'im_info'
  bottom: 'fg_inds'
  bottom: 'bg_inds'
  top: 'rpn_labels'
  top: 'rpn_bbox_targets'
  top: 'rpn_bbox_inside_weights'
  top: 'rpn_bbox_outside_weights'
  python_param {
    module: 'pylayer.anchor_target_layer'
    layer: 'AnchorTargetLayer'
    param_str: "{'feat_stride': 16}"
  }
}

#------------ RPN loss ------------
# put rpn loss here since we need
# proposal's index first

layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  propagate_down: 1
  propagate_down: 0
  top: "rpn_cls_loss"
  loss_weight: 1
  loss_param {
    ignore_label: -1
    normalize: true
  }
}

layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: 'rpn_bbox_inside_weights'
  bottom: 'rpn_bbox_outside_weights'
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param { sigma: 3.0 }
}

#------------ Roi Warping ------------

layer {
  name: "roi_interpolate_conv5"
  type: "ROIWarping"
  bottom: "conv5_3"
  bottom: "rois"
  propagate_down: 1
  propagate_down: 1
  top: "roi_interpolate_conv5"
  roi_warping_param {
    pooled_w: 14
    pooled_h: 14
    spatial_scale: 0.0625 # 1/16
  }
}

#------------ Mask Estimation ------------

layer {
  name: "fc6_maskest"
  type: "InnerProduct"
  bottom: "roi_interpolate_conv5"
  top: "fc6_maskest"
  param {
    name: "fc6_maskest_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc6_maskest_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu6_maskest"
  type: "ReLU"
  bottom: "fc6_maskest"
  top: "fc6_maskest"
}

layer {
  name: "mask_pred"
  type: "InnerProduct"
  bottom: "fc6_maskest"
  top: "mask_pred"
  param {
    name: "mask_pred_w" 
    lr_mult: 1.0 
  }
  param {
    name: "mask_pred_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 441 # 21 * 21
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_mask"
  type: "SigmoidCrossEntropyLoss"
  bottom: "mask_pred"
  bottom: "mask_targets"
  bottom: "mask_weight"
  propagate_down: 1
  propagate_down: 0
  propagate_down: 0
  top: "loss_mask"
  loss_weight: 2
}

#------------ Mask resize ------------
# get masks from sigmoid prediction 
# and use it for mask pooling

layer {
  name: "mask_output"
  type: "Sigmoid"
  bottom: "mask_pred"
  top: "mask_output"
}

layer {
  name: "mask_proposal"
  type: 'Python'
  bottom: 'mask_output'
  bottom: 'gt_masks'
  bottom: 'gt_masks_info'
  propagate_down: 1
  propagate_down: 0
  propagate_down: 0
  top: 'mask_proposal'
  top: 'mask_proposal_label'
  python_param {
    module: 'pylayer.mask_layer'
    layer: 'MaskLayer'
  }
}

layer {
  name: "mask_resize"
  type: "MaskResize"
  bottom: "mask_proposal"
  top: "mask_proposal_resize"
  mask_resize_param {
    output_height: 14
    output_width: 14
  }
}

#------------ Box Features ------------

layer {
  name: "roi_interpolate_conv5_box"
  type: "Pooling"
  bottom: "roi_interpolate_conv5"
  top: "roi_interpolate_conv5_box"
  pooling_param {
    kernel_size: 2
    stride: 2
    pad: 0
    pool: MAX
  }
}

layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "roi_interpolate_conv5_box"
  top: "fc6"
  param {
    name: "fc6_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc6_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}

layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc7_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}

#------------ Mask Features ------------

layer {
  name: "mask_pooling"
  type: "MaskPooling"
  propagate_down: 1
  propagate_down: 1
  bottom: "roi_interpolate_conv5"
  bottom: "mask_proposal_resize"
  top: "roi_mask_conv5"
}

layer {
  name: "roi_interpolate_conv5_mask"
  type: "Pooling"
  bottom: "roi_mask_conv5"
  top: "roi_interpolate_conv5_mask"
  pooling_param {
    kernel_size: 2
    stride: 2
    pad: 0
    pool: MAX
  }
}

layer {
  name: "fc6_mask"
  type: "InnerProduct"
  bottom: "roi_interpolate_conv5_mask"
  top: "fc6_mask"
  param {
    name: "fc6_mask_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc6_mask_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu6_mask"
  type: "ReLU"
  bottom: "fc6_mask"
  top: "fc6_mask"
}

layer {
  name: "fc7_mask"
  type: "InnerProduct"
  bottom: "fc6_mask"
  top: "fc7_mask"
  param {
    name: "fc7_mask_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc7_mask_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu7_mask"
  type: "ReLU"
  bottom: "fc7_mask"
  top: "fc7_mask"
}

#----- Concat Box-Mask Feature -----

layer {
  name: "join_box_mask"
  type: "Concat"
  bottom: "fc7_mask"
  bottom: "fc7"
  top: "join_box_mask"
  concat_param {
    axis: 1
  }
}

#----- Box-level Classification -----

layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "join_box_mask"
  top: "cls_score"
  param {
    name: "cls_score_w" 
    lr_mult: 1.0 
  }
  param {
    name: "cls_score_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  propagate_down: 1
  propagate_down: 0
  top: "cls_loss"
  loss_weight: 1
  loss_param {
    ignore_label: -1
    normalize: true
  }
}

#----- Mask-level Classification -----

layer {
  name: "seg_cls_score"
  type: "InnerProduct"
  bottom: "join_box_mask"
  top: "seg_cls_score"
  param {
    name: "seg_cls_score_w" 
    lr_mult: 1.0 
  }
  param {
    name: "seg_cls_score_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_seg_cls"
  type: "SoftmaxWithLoss"
  bottom: "seg_cls_score"
  bottom: "mask_proposal_label"
  propagate_down: 1
  propagate_down: 0
  top: "seg_cls_loss"
  loss_weight: 1.0
  loss_param {
    ignore_label: -1
    normalize: true
  }
}

#----- Bounding-box Regression -----

layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "join_box_mask"
  top: "bbox_pred"
  param {
    name: "bbox_pred_w" 
    lr_mult: 1.0 
  }
  param {
    name: "bbox_pred_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: 'bbox_inside_weights'
  bottom: 'bbox_outside_weights'
  top: "bbox_loss"
  loss_weight: 1
}

layer {
  name: "accuracy_seg"
  type: "Accuracy"
  bottom: "seg_cls_score"
  bottom: "mask_proposal_label"
  top: "accuracy_seg"
}

layer {
  name: "accuracy_det"
  type: "Accuracy"
  bottom: "cls_score"
  bottom: "labels"
  top: "accuracy_det"
}

# --------- Next Stage ----------
# We extend 3 stage mnc to 5 stage
# layer structure are mostly similar
# name are suffixed by _ext (extend)

layer {
  name: "seg_cls_prob"
  type: "Softmax"
  bottom: "seg_cls_score"
  top: "seg_cls_prob"
  loss_param {
    ignore_label: -1
    normalize: true
  }
}

layer {
  name: "stage_bridge"
  type: 'Python'
  bottom: 'rois'
  bottom: 'bbox_pred'
  bottom: 'seg_cls_prob'
  bottom: 'gt_boxes'
  bottom: 'gt_masks'
  bottom: 'im_info'
  bottom: 'mask_info'
  propagate_down: 1
  propagate_down: 1
  propagate_down: 0
  propagate_down: 0
  propagate_down: 0
  propagate_down: 0
  propagate_down: 0
  top: 'rois_ext'
  top: 'labels_ext'
  top: 'mask_targets_ext'
  top: 'mask_weight_ext'
  top: 'gt_masks_info_ext'
  top: 'bbox_targets_ext'
  top: 'bbox_inside_weights_ext'
  top: 'bbox_outside_weights_ext'
  python_param {
    module: 'pylayer.stage_bridge_layer'
    layer: 'StageBridgeLayer'
    param_str: "{ 'feat_stride': 16,  'use_clip': 1,  'clip_base': 512 }"
  }
}

#------------ Roi Warping Ext ------------

layer {
  name: "roi_interpolate_conv5_ext"
  type: "ROIWarping"
  bottom: "conv5_3"
  bottom: "rois_ext"
  propagate_down: 1
  propagate_down: 1
  top: "roi_interpolate_conv5_ext"
  roi_warping_param {
    pooled_w: 14
    pooled_h: 14
    spatial_scale: 0.0625 # 1/16
  }
}

#------------ Mask Estimation Ext ------------

layer {
  name: "fc6_maskest_ext"
  type: "InnerProduct"
  bottom: "roi_interpolate_conv5_ext"
  top: "fc6_maskest_ext"
  param {
    name: "fc6_maskest_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc6_maskest_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu6_maskest_ext"
  type: "ReLU"
  bottom: "fc6_maskest_ext"
  top: "fc6_maskest_ext"
}

layer {
  name: "mask_pred_ext"
  type: "InnerProduct"
  bottom: "fc6_maskest_ext"
  top: "mask_pred_ext"
  param {
    name: "mask_pred_w" 
    lr_mult: 1.0 
  }
  param {
    name: "mask_pred_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 441 # 21 * 21
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_mask_ext"
  type: "SigmoidCrossEntropyLoss"
  bottom: "mask_pred_ext"
  bottom: "mask_targets_ext"
  bottom: "mask_weight_ext"
  propagate_down: 1
  propagate_down: 0
  propagate_down: 0
  top: "loss_mask_ext"
  loss_weight: 2
}

#------------ Mask Resize ------------
# get masks from sigmoid prediction 
# and use it for mask pooling

layer {
  name: "mask_output_ext"
  type: "Sigmoid"
  bottom: "mask_pred_ext"
  top: "mask_output_ext"
}

layer {
  name: "mask_proposal_ext"
  type: 'Python'
  bottom: 'mask_output_ext'
  bottom: 'gt_masks'
  bottom: 'gt_masks_info_ext'
  propagate_down: 1
  propagate_down: 0
  propagate_down: 0
  top: 'mask_proposal_ext'
  top: 'mask_proposal_label_ext'
  python_param {
    module: 'pylayer.mask_layer'
    layer: 'MaskLayer'
  }
}

layer {
  name: "mask_resize_ext"
  type: "MaskResize"
  bottom: "mask_proposal_ext"
  top: "mask_proposal_resize_ext"
  mask_resize_param {
    output_height: 14
    output_width: 14
  }
}

#------------ Box Features Ext ------------

layer {
  name: "roi_interpolate_conv5_box_ext"
  type: "Pooling"
  bottom: "roi_interpolate_conv5_ext"
  top: "roi_interpolate_conv5_box_ext"
  pooling_param {
    kernel_size: 2
    stride: 2
    pad: 0
    pool: MAX
  }
}

layer {
  name: "fc6_ext"
  type: "InnerProduct"
  bottom: "roi_interpolate_conv5_box_ext"
  top: "fc6_ext"
  param {
    name: "fc6_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc6_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu6_ext"
  type: "ReLU"
  bottom: "fc6_ext"
  top: "fc6_ext"
}

layer {
  name: "fc7_ext"
  type: "InnerProduct"
  bottom: "fc6_ext"
  top: "fc7_ext"
  param {
    name: "fc7_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc7_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu7_ext"
  type: "ReLU"
  bottom: "fc7_ext"
  top: "fc7_ext"
}

# ------ Mask Feature Ext ---------

layer {
  name: "mask_pooling_ext"
  type: "MaskPooling"
  propagate_down: 1
  propagate_down: 1
  bottom: "roi_interpolate_conv5_ext"
  bottom: "mask_proposal_resize_ext"
  top: "roi_mask_conv5_ext"
}

layer {
  name: "roi_interpolate_conv5_mask_ext"
  type: "Pooling"
  bottom: "roi_mask_conv5_ext"
  top: "roi_interpolate_conv5_mask_ext"
  pooling_param {
    kernel_size: 2
    stride: 2
    pad: 0
    pool: MAX
  }
}

layer {
  name: "fc6_mask_ext"
  type: "InnerProduct"
  bottom: "roi_interpolate_conv5_mask_ext"
  top: "fc6_mask_ext"
  param {
    name: "fc6_mask_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc6_mask_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu6_mask_ext"
  type: "ReLU"
  bottom: "fc6_mask_ext"
  top: "fc6_mask_ext"
}

layer {
  name: "fc7_mask_ext"
  type: "InnerProduct"
  bottom: "fc6_mask_ext"
  top: "fc7_mask_ext"
  param {
    name: "fc7_mask_w" 
    lr_mult: 1.0 
  }
  param {
    name: "fc7_mask_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 4096
  }
}

layer {
  name: "relu7_mask_ext"
  type: "ReLU"
  bottom: "fc7_mask_ext"
  top: "fc7_mask_ext"
}

#----- Concat Box-Mask Feature -----

layer {
  name: "join_box_mask_ext"
  type: "Concat"
  bottom: "fc7_mask_ext"
  bottom: "fc7_ext"
  top: "join_box_mask_ext"
  concat_param {
    axis: 1
  }
}

#----- Box-level Classification -----

layer {
  name: "cls_score_ext"
  type: "InnerProduct"
  bottom: "join_box_mask_ext"
  top: "cls_score_ext"
  param {
    name: "cls_score_w" 
    lr_mult: 1.0 
  }
  param {
    name: "cls_score_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_cls_ext"
  type: "SoftmaxWithLoss"
  bottom: "cls_score_ext"
  bottom: "labels_ext"
  propagate_down: 1
  propagate_down: 0
  top: "cls_loss_ext"
  loss_weight: 1
  loss_param {
    ignore_label: -1
    normalize: true
  }
}

#----- Mask-level Classification -----

layer {
  name: "seg_cls_score_ext"
  type: "InnerProduct"
  bottom: "join_box_mask_ext"
  top: "seg_cls_score_ext"
  param {
    name: "seg_cls_score_w" 
    lr_mult: 1.0 
  }
  param {
    name: "seg_cls_score_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_seg_cls_ext"
  type: "SoftmaxWithLoss"
  bottom: "seg_cls_score_ext"
  bottom: "mask_proposal_label_ext"
  propagate_down: 1
  propagate_down: 0
  top: "seg_cls_loss_ext"
  loss_weight: 1
  loss_param {
    ignore_label: -1
    normalize: true
  }
}

#----- Bounding-box Regression -----

layer {
  name: "bbox_pred_ext"
  type: "InnerProduct"
  bottom: "join_box_mask_ext"
  top: "bbox_pred_ext"
  param {
    name: "bbox_pred_w" 
    lr_mult: 1.0 
  }
  param {
    name: "bbox_pred_b" 
    lr_mult: 2.0 
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss_bbox_ext"
  type: "SmoothL1Loss"
  bottom: "bbox_pred_ext"
  bottom: "bbox_targets_ext"
  bottom: 'bbox_inside_weights_ext'
  bottom: 'bbox_outside_weights_ext'
  top: "bbox_loss_ext"
  loss_weight: 1
}


layer {
  name: "accuracy_seg_ext"
  type: "Accuracy"
  bottom: "seg_cls_score_ext"
  bottom: "mask_proposal_label_ext"
  top: "accuracy_seg_ext"
}

layer {
  name: "accuracy_det_ext"
  type: "Accuracy"
  bottom: "cls_score_ext"
  bottom: "labels_ext"
  top: "accuracy_det_ext"
}
